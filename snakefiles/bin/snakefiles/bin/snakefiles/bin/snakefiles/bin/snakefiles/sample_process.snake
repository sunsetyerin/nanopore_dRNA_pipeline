#!/usr/bin/env python3
# coding=utf-8

__author__ = "Jean-Michel Garant"
__copyright__ = "Copyright (C) 2020, " + __author__
__email__ = "jmgarant@bcgsc.ca"
__license__ = "GPLv3"

localrules: install_guppy,
            tailfindr_butler,
            tailfindr_catenation,
            summary_tailfindr,
            fastq_catenation,
            install_albacore,
            fasta_index,
            fasta_dict,

include: "common.snake"

configfile: "configs/sample_config.yaml"

rule all_targets:
    """
    Generate default target files.
    """
    input:
        expand(os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "plots",
            "polya_tails_len_bins.html"
            ), sample=list(config["samples"].keys())),

rule install_guppy:
    """
    Install Guppy from the provided tar.gz package.
    Current Guppy version supported: 4.0.11
    """
    input:
        targz = config["guppy"]["compressed_tarball_path"],
    output:
        installed = os.path.join("data", "guppy", "guppy.touch"),
        guppy_dir = directory(os.path.join("bin", "ont-guppy")),
    log:
        os.path.join("logs", "guppy", "guppy_installation.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 1,
        time_limit = 1200,
        mem_mb = 32000,
    shell:
        " ".join(["tar -zxC ./bin",
                  "-f {input.targz}",
                  #"{output.guppy_dir}",
                  "&> >(tee {log}) && touch {output.installed}"])

checkpoint guppy_basecall:
    """
    Runs a basecall using guppy in order to get the move table in the
    fast5 files.
    *** This job is meant to be run on slurmgpu/dlhosts ***
    *** before the rest of the workflow.                ***
    """
    input:
        fast5_dir = fast5_directory,
        fast5_files = fast5_files,
        installed = os.path.join("data", "guppy", "guppy.touch"),        
    params:
        flowcell_config = config["guppy"]["flowcell_config"],
        devices = config["guppy"]["device_string"],
    output:
        guppy_fast5 = directory(
            os.path.join(
                "data",
                "{sample}",
                "guppy_basecall",
                "workspace",
                ),
            ),
        guppy_fastq_gz = directory(
            os.path.join(
                "data",
                "{sample}",
                "guppy_basecall",
                "pass",
                ),
            ),
        sequencing_summary = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "sequencing_summary.txt",
            ),
    log:
        os.path.join("logs", "guppy", "{sample}_guppy_basecall.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 4320,
        mem_mb = 32000,
    shell:
        " ".join(["OUTPUT=({output.guppy_fast5});",
                  os.path.join("bin", "ont-guppy", "bin", "guppy_basecaller"),  # "{params.guppy}",
                  "-i {input.fast5_dir}",
                  "-s ${{OUTPUT%/workspace}}",
                  "-c {params.flowcell_config}",
                  "--device \"{params.devices}\"",
                  "--gpu_runners_per_device 8",
                  "--qscore_filtering",
                  "--records_per_fastq 0",
                  "--compress_fastq",
                  "--u_substitution true",
                  "--fast5_out"])

rule tailfindr_butler:
    """
    TailfindR native parallelization is insufficient for very large
    runs.  Since, the find_tails() function can only be supplied with a
    directory path and all fast5 generated by guppy_basecaller are in
    the same directory. This butler generates temporary directories with
    symlinks towards the different sampling of the .fast5 files.
    """
    input:
        fast5_dir = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "workspace",
            "{fast5}.fast5"
            ),
        basecall_summary = os.path.join(  # TODO placeholder
            "data",
            "{sample}",
            "guppy_basecall",
            "sequencing_summary.txt",
            ),
    output:
        fast5_sym = temp(os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "tmp_workspace",
            "{fast5}",
            "{fast5}.fast5"
            )),
    log:
        os.path.join("logs", "tailfindr", "{sample}_{fast5}.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    shell:
        " ".join(["ln -sr",
                  "{input.fast5_dir}",
                  "{output.fast5_sym}"])

rule tailfindr:
    """
    Runs taildfindr on the set of fast5 files provided in the input
    directory. Tailfindr will evaluate the length of poly-A tails from
    reads supplied.

    *** Requires event/move table in the .fast5. ***
    """
    input:
        fast5_file = os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "tmp_workspace",
            "{fast5}",
            "{fast5}.fast5"
            ),
    params:
        tail_plots = config["tailfindr"]["tail_plots.html"],
        debug_traces = config["tailfindr"]["debug_traces"],
        num_cores_per_jobs = config["tailfindr"]["cores_per_tailfindr_jobs"],
    output:
        tails_out = temp(os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "tmp_csv",
            "{fast5}",
            "polya_tails.csv"
            )),
    log:
        os.path.join("logs", "tailfindr", "{sample}_{fast5}.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 48,
        time_limit = 2400,
        mem_mb = 64000,
    script:
        "bin/tailfindr.R"

rule tailfindr_catenation:
    """
    Each tailfindr jobs produces a temp .csv file of the reads it
    processed. The .csv files are concatenated in a single .csv.
    """
    input:
        aggregate_csv_names
    output:
        cat_csv = os.path.join(
            "data",
            "{sample}", 
            "tailfindr",     
            "polya_tails.csv"
            ),               
    log:
        os.path.join("logs", "tailfindr", "{sample}_concat.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    shell:                   
        "echo \"read_id,tail_start,tail_end,samples_per_nt,tail_length,"
            "file_path\" > {output.cat_csv} && "
        "cat {input} | grep  -v \"read_id,tail_start,tail_end,samples_per_nt,"
            "tail_length,file_path\" >> {output.cat_csv}"

rule summary_tailfindr:
    """
    Generate a binned histogram of the distribution of polyA tails in
    the sample. 
    """
    input:
        polya_csv = os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "polya_tails.csv"
            ),
    output:
        fig_html = os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "plots",
            "polya_tails_len_bins.html"
            ),
    log:
        os.path.join("logs", "tailfindr", "{sample}_summary.log")
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    script:
        "bin/sum_tailfindr.py"

rule fastq_catenation:
    """
    Create a single fastq out of guppy output.
    """
    input:
        fastqs = aggregate_fastq,
        ### fastqs are often too numerous for snakemake to handle,
        ### therefore this rule rely on the directory as input as well
        fastq_dir = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "pass"),
    output:
        fastq = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "pass_catenated.fastq.gz"),
    #log:
    #    os.path.join("logs", "guppy", "{sample}_cat.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    shell:
        ### On paper a simple 
        # "cat {input.fastqs} > {output.fastq}"
        ### should do, but in practice the large number of files 
        ### generated by guppy requires the replacement the explicit
        ### listing of input to a starred (*) solution
        os.path.join("cat {input.fastq_dir}", "*.fastq.gz > {output.fastq}")

rule flair_alignment:
    """
    Alignment to a reference genome in fasta format using minimap2.
    """
    input:
        genomic_fasta = config["genomic_fasta"],
        chr_sizes = config["chr_sizes"],
        read = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "{fastq_file}.fastq.gz"),
    output:
        flair_aligned = multiext(
            os.path.join(
                "data",
                "{sample}",
                "flair",
                "{fastq_file}.aligned"),
            ".bam", ".bam.bai", ".bed", ".psl", ".sam"),
    log:
        os.path.join("logs", "flair", "{sample}_{fastq_file}_align.log"),
    conda:
        os.path.join(
            "..",
            "submodules",
            "flair",
            "misc",
            "flair_conda_env.yaml"
            ),
    resources:
        cpus = 48,
        time_limit = 600,
        mem_mb = 32000,
    shell:
        " ".join(["python",
                  os.path.join("submodules", "flair", "flair.py"), 
                  "align",
                  "-r {input.read}",
                  "-g {input.genomic_fasta}",
                  "-p",
                  "-c {input.chr_sizes}",
                  "-o $(echo {output.flair_aligned}",
                  "| grep -Po '\S*(?=\.bed)')",
                  "&> >(tee {log})"])

rule flair_correction:
    """
    Correction of alignement at exons junctions used to define isoforms
    present in reads.
    """
    input:
        genomic_fasta = config["genomic_fasta"],
        genomic_annotation = config["annotation_file"],
        chr_sizes = config["chr_sizes"],
        flair_aligned = os.path.join(
            "data",
            "{sample}",
            "flair",
            "{fastq_file}.bed"
            ),
    output:
        flair_corrected = multiext(
            os.path.join(
                "data",
                "{sample}",
                "flair",
                "{fastq_file}_all_corrected"),
            ".bed", ".psl"),
#        flair_inconsistent = os.path.join(
#            "data",
#            "{sample}",
#            "flair",
#            "{fastq_file}_all_inconsistent.bed"),
    log:
        os.path.join("logs", "flair", "{sample}_{fastq_file}_correct.log"),
    conda:
        os.path.join(
            "..",
            "submodules",
            "flair",
            "misc",
            "flair_conda_env.yaml"
            ),
    resources:
        cpus = 48,
        time_limit = 600,
        mem_mb = 32000,
    shell:
        " ".join(["python",
                  os.path.join("submodules", "flair", "flair.py"), 
                  "correct",
                  "-q {input.flair_aligned}",
                  "-g {input.genomic_fasta}",
                  "-f {input.genomic_annotation}",
                  "-c {input.chr_sizes}",
                  "-o $(echo {output.flair_corrected}",
                  "| grep -Po '\S*(?=_all_corrected\.bed)')",
                  "&> >(tee {log})"
                  ])

rule flair_collapse:
    """
    Obtaining map of reads on transcripts/genes. Built upon Cameron
    Grisdale work using flair to measure gene expression.
    """
    input:
        genomic_fasta = config["genomic_fasta"],
        annotation = config["annotation_file"],
        reads_fastq_gz = os.path.join(
            "data",
            "{sample}",
            "guppy_basecall",
            "{fastq_file}.fastq.gz"),
        alignment_corrected = os.path.join(
            "data",
            "{sample}",
            "flair",
            "{fastq_file}.aligned_all_corrected.psl"),
    params:
        thr = config["flair"]["threads"],
    output:
        isoforms = multiext(
            os.path.join(
                "data",
                "{sample}",
                "flair",
                "{fastq_file}.isoforms"),
            ".fa", ".gtf", ".psl"),
        read_map = os.path.join(
            "data",
            "{sample}",
            "flair",
            "{fastq_file}.isoform.read.map.txt"),
    log:
        os.path.join("logs", "flair", "{sample}_{fastq_file}_collapse.log"),
    conda:
        os.path.join(
            "..",
            "submodules",
            "flair",
            "misc",
            "flair_conda_env.yaml"
            ),
    resources:
        cpus = 48,
        time_limit = 600,
        mem_mb = 32000,
    shell:
        " ".join(["python",
                  os.path.join("submodules", "flair", "flair.py"), 
                  "collapse",
                  "-g {input.genomic_fasta}",
                  "-r {input.reads_fastq_gz}",
                  "-q {input.alignment_corrected}",
                  "-f {input.annotation}",
                  "-t {params.thr}",
                  "--generate_map",
                  "-e ginormous",
                  "-o $(echo {output.read_map}",
                  "| grep -Po '\S*(?=\.isoform\.read\.map\.txt)')",
                  "&> >(tee {log})"])

rule match_reads_polya_tpm:
    """
    Join gene expression determined by Flair with polyA tails from
    TailfindR.
    """
    input:
        read_map = os.path.join(
            "data",
            "{sample}",
            "flair",
            "pass_catenated.isoform.read.map.txt"
            ),
        gene_expression = gene_expression,
        polya_tails = os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "polya_tails.csv"
            ),
    output:
        gene_to_polya = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "pass_catenated.gene_exp_polya_tails.tsv"
            ),
    log:
        os.path.join("logs", "{sample}_match_polya_tpm.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 1200,
        mem_mb = 32000,
    script:
        os.path.join("bin", "polya_tails_map.py")

rule match_reads_polya_flair_state:
    """
    Join Flair output with polyA tails from TailfindR.
    """
    input:
        read_map = os.path.join(
            "data",
            "{sample}",
            "flair",
            "pass_catenated.isoform.read.map.txt"
            ),
        polya_tails = os.path.join(
            "data",
            "{sample}",
            "tailfindr",
            "polya_tails.csv"
            ),
    output:
        flair_reads_and_polya = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "pass_catenated.flair_state_polya_tails.tsv"
            ),
    log:
        os.path.join("logs", "{sample}_flair_polya.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 1200,
        mem_mb = 32000,
    script:
        os.path.join("bin", "dropped_read_analysis.py")

rule install_albacore:
    """
    Since Albacore is deprecated, this rule install it from a .whl package
    included in the "bin" directory.
    """
    input:
        whl = config["albacore"]["whl_package_path"],
    output:
        installed = os.path.join("data", "albacore", "albacore.touch"),
    log:
        os.path.join("logs", "albacore", "albacore_installation.log"),
    conda:
        os.path.join("..", "envs", "albacore.yaml"),
    resources:
        cpus = 1,
        time_limit = 1200,
        mem_mb = 32000,
    shell:
        " ".join(["pip install",
                  "seamlessf5",
                  "{input.whl}",
                  "&> >(tee {log})",
                  "&& touch {output.installed}"])

checkpoint albacore_basecall:
    """
    Runs a basecall using albacore in order to get the error prone fast5 file
    that supports the m6A modification call by EpiNano.
    """
    input:
        fast5_dir = fast5_directory,
        fast5_files = fast5_files,
        installed = os.path.join("data", "albacore", "albacore.touch"),
    params:
        flowcell = config["albacore"]["flowcell"],
        kit = config["albacore"]["kit"],
        threads = config["albacore"]["threads"],
    output:
        albacore_out = directory(
            os.path.join(
                "data",
                "{sample}",
                "albacore",
                ),
            ),
    log:
        os.path.join("logs", "albacore", "{sample}", "albacore_basecall.log"),
    conda:
        os.path.join("..", "envs", "albacore.yaml"),
    resources:
        cpus = 48,
        time_limit = 8640,
        mem_mb = 32000,
    shell:
        " ".join(["sf5_read_fast5_basecaller.py",
                  "-i {input.fast5_dir}",
                  "-s {output.albacore_out}",
                  "-f {params.flowcell}",
                  "-k {params.kit}",
                  "-t {params.threads}",
                  "-o fastq",
                  "--resume"
                  "-q 0",
                  "--disable_filtering"])

rule fasta_index:
    """
    Samtools indexation of a genomic reference fasta.
    """
    input:
        genomic_fasta = "{fasta}",
    output:
        indexed_fasta = "{fasta}.fai",
    log:
        os.path.join("logs", "{fasta}_indexation.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 1,
        time_limit = 1200,
        mem_mb = 32000,
    shell:
        " ".join(["samtools faidx",
                  "-f {input.genomic_fasta}",
                  "-o {output.indexed_fasta}",
                  "&> >(tee {log})"])

rule fasta_dict:
    """
    Generate the sequence dictionnary of a fasta file.
    """
    input:
        transcriptome_fasta = config["genomic_fasta"],
    output:
        dict_fasta = "".join([os.path.splitext(config["genomic_fasta"])[0],
                             ".dict"]),
    log:
        os.path.join("logs", "reference_dict.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 1200,
        mem_mb = 32000,
    shell:
        " ".join(["java -jar",
                  os.path.join("bin", "picard.jar"),
                  "CreateSequenceDictionary",
                  "R={input.transcriptome_fasta}",
                  "&> >(tee {log})"])

rule epinano_mapping:
    """
    Maps Albacore basecalled reads to a reference (fasta) using its index and
    dictionnary.
    """
    input:
#        fastq = get_albacore_fastq,
        fastq = os.path.join(
            "data",
            "{sample}",
            "albacore",
            "workspace",
            "{fastq}.fastq"),
        transcriptome_fasta = config["genomic_fasta"],
        indexed_fasta = "".join([config["genomic_fasta"], ".fai"]),
        dict_fasta = "".join([os.path.splitext(config["genomic_fasta"])[0],
                             ".dict"]),
        albacore_out = os.path.join(
            "data",
            "{sample}",
            "albacore"),
    output:
        bam = temp(os.path.join(
            "data",
            "{sample}",
            "epinano",
            "{fastq}.bam")),
        bam_index = temp(os.path.join(
            "data",
            "{sample}",
            "epinano",
            "{fastq}.bam.bai")),
    log:
        os.path.join("logs", "{sample}_{fastq}_epinano_map.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 2400,
        mem_mb = 32000,
    shell:
        " ".join(["minimap2 -ax map-ont",
                  "{input.transcriptome_fasta}",
                  "{input.fastq} |",
                  "samtools view -hSb - |",
                  "samtools sort -@ {resources.cpus} - -o {output.bam}",
                  "&> >(tee {log}) &&",
                  "samtools index {output.bam}",
                  "&>> >(tee {log})"])

rule epinano_variants:
    """
    Calls m6A positions using indels/mismatches in the mapping.
    """
    input:
        bam = os.path.join(
            "data",
            "{sample}",
            "epinano",
            "{fastq}.bam"),
        bam_index = os.path.join(
            "data",
            "{sample}",
            "epinano",
            "{fastq}.bam.bai"),
        transcriptome_fasta = config["genomic_fasta"],
    output:
        tsv = os.path.join(
            "data",
            "{sample}",
            "epinano",
            "{fastq}.tsv"),
        multi = multiext(
            os.path.join(
                "data",
                "{sample}",
                "epinano",
                "{fastq}"),
            ".tsv.per.site.var.csv",
            ".tsv.per.site.var.per_site_var.5mer.csv"),
    log:
        os.path.join("logs", "{sample}_{fastq}_epinano_variants.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 2400,
        mem_mb = 32000,
    shell:
        " ".join(["samtools view",
                  "-h -F 3844 {input.bam} |",
                  "sam2tsv -r {input.transcriptome_fasta}",
                  "> {output.tsv}",
                  "&> >(tee {log}) &&",
                  "python",
                  os.path.join("submodules", "EpiNano", "scripts",
                               "TSV_to_Variants_Freq.py3"),
                  "-f {output.tsv}",
                  "-t 10",
                  "&>> >(tee {log})"])

rule downstream_epinano:
    """
    """
    input:
        stuff = get_albacore_epinano,
    output:
        summary = os.path.join(
            "data",
            "{sample}",
            "epinano",
            "epinano_summary.txt"),
    log:
        os.path.join("logs", "{sample}_epinano_summary.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 600,
        mem_mb = 32000,
    shell:
        "echo \"{input.stuff}\" > {output.summary}"

rule scatter_plots:
    """
    Generates an interactive scatterplot from a csv.
    """
    input:
        mapped = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "{tsv_file}.tsv"
            )
    params:
        x_axis = "flair_state", #  "tail_length_mean",
        group_column = "tail_length", #  "TPMGroup"
    output:
        plotly_fig = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "{tsv_file}_scatter.html"
            )
    log:
        os.path.join("logs", "{sample}_{tsv_file}.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 1200,
        mem_mb = 32000,
    script:
        "bin/exp_tail_plot.py"

rule comparative_plots:
    """
    Generates an interactive scatterplot from a csv.
    """
    input:
        mapped = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "{tsv_file}.tsv"
            )
    params:
        x_axis = "samples_per_nt", #  "tail_length_mean",
        group_column = "flair_state", #  "TPMGroup"
    output:
        plotly_fig = os.path.join(
            "data",
            "{sample}",
            "integrated_data",
            "{tsv_file}_bar_.svg"
            )
    log:
        os.path.join("logs", "{sample}_{tsv_file}.log"),
    conda:
        os.path.join("..", "envs", "environment.yaml"),
    resources:
        cpus = 4,
        time_limit = 1200,
        mem_mb = 32000,
    script:
        "bin/drop_tail_plot.py"
